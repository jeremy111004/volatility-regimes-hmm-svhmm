# üì¶ Imports
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
import seaborn as sns

# ‚úÖ √âtape 1 - R√©cup√©ration des donn√©es
data = yf.download('^GSPC', start='2000-01-01', end='2025-04-01')

# ‚úÖ √âtape 2 - Calcul des log-returns
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data = data.dropna()

# ‚úÖ √âtape 3 - Pr√©paration des donn√©es pour le mod√®le
returns = data['Log_Returns'].values.reshape(-1, 1)

# ‚úÖ √âtape 4 - HMM √† 3 √©tats
model = GaussianHMM(n_components=3, covariance_type='full', n_iter=1000)
model.fit(returns)

# ‚úÖ √âtape 5 - Pr√©diction des √©tats cach√©s
hidden_states = model.predict(returns)

# ‚úÖ √âtape 5 bis - Reclasser les r√©gimes par ordre de volatilit√©
state_variances = [np.var(returns[hidden_states == i]) for i in range(3)]
sorted_states = np.argsort(state_variances)  # indices des r√©gimes tri√©s
remap = {old: new for new, old in enumerate(sorted_states)}
remapped_states = np.vectorize(remap.get)(hidden_states)
data['Hidden_State'] = remapped_states

# ‚úÖ √âtape 6 - Visualisation des r√©gimes
colors = ['green', 'orange', 'red']  # 0 = calme, 2 = crise
plt.figure(figsize=(15, 7))
for i in range(3):
    state = (data['Hidden_State'] == i)
    plt.plot(data.index[state], data['Log_Returns'][state], '.', label=f"R√©gime {i}", color=colors[i], alpha=0.6)

plt.title("R√©gimes de march√© d√©tect√©s par un HMM √† 3 √©tats sur le S&P 500")
plt.xlabel("Date")
plt.ylabel("Log-returns")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ‚úÖ √âtape 7 - Statistiques de chaque r√©gime
print("Statistiques par r√©gime d√©tect√© (class√©s par volatilit√© croissante) :\n")
for i in range(3):
    mask = (data['Hidden_State'] == i)
    mean = data['Log_Returns'][mask].mean()
    var = data['Log_Returns'][mask].var()
    print(f"R√©gime {i} : Moyenne = {mean:.5f}, Variance = {var:.5f}")

# ‚úÖ Volatilit√© implicite estim√©e
data['Variance_estimee'] = [model.covars_[hidden_states[i]][0][0] for i in range(len(hidden_states))]
plt.figure(figsize=(14, 5))
plt.plot(data.index, np.sqrt(data['Variance_estimee']) * np.sqrt(252))  # Annualis√©e
plt.title("Volatilit√© implicite estim√©e par le HMM")
plt.ylabel("Volatilit√© (annualis√©e)")
plt.xlabel("Date")
plt.grid(True)
plt.show()

# ‚úÖ Bande verticale color√©e
fig, ax = plt.subplots(figsize=(14, 6))
ax.plot(data.index, data['Log_Returns'], color='black', lw=0.5, label="Log-returns")
colors_map = {0: 'green', 1: 'orange', 2: 'red'}
hidden_colors = data['Hidden_State'].map(colors_map)
for i in range(len(data)):
    ax.axvline(data.index[i], color=hidden_colors[i], alpha=0.01)

ax.set_title("Log-Returns avec r√©gimes de volatilit√© d√©tect√©s (tri√©s)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# ‚úÖ Dur√©e moyenne par r√©gime
print("\nDur√©e moyenne par r√©gime :")
for i in range(3):
    durations = data['Hidden_State'].eq(i).astype(int).groupby((data['Hidden_State'] != i).cumsum()).sum()
    print(f"R√©gime {i} : {durations.mean():.2f} jours")

# ‚úÖ Matrice de transition
# On r√©organise les lignes/colonnes de la matrice pour correspondre au nouveau mapping
trans_mat_sorted = model.transmat_[sorted_states, :][:, sorted_states]
trans_df = pd.DataFrame(trans_mat_sorted, columns=[f'R√©gime {i}' for i in range(3)], index=[f'R√©gime {i}' for i in range(3)])
sns.heatmap(trans_df, annot=True, cmap='Blues', fmt=".2f")
plt.title("Matrice de transition du HMM (tri√©e par volatilit√©)")
plt.show()
# Dernier √©tat estim√©
last_state = hidden_states[-1]

# Matrice de transition
A = model.transmat_

# Probabilit√© d'√™tre dans chaque √©tat demain
proba_next = A[last_state]

# Affichage
print("\n Pr√©vision pour demain :")
for i, p in enumerate(proba_next):
    print(f"‚Üí Probabilit√© d'√™tre en R√©gime {i} : {p:.2%}")

# √âtat le plus probable
regime_prevu = np.argmax(proba_next)
print(f"\n R√©gime le plus probable demain : R√©gime {regime_prevu}")

import seaborn as sns

plt.figure(figsize=(6, 4))
sns.barplot(x=[f"R√©gime {i}" for i in range(3)], y=proba_next, palette=colors)
plt.title("Probabilit√© de chaque r√©gime demain")
plt.ylim(0, 1)
plt.ylabel("Probabilit√©")
plt.grid(True, axis='y')
plt.tight_layout()
plt.show()
STATIC HMM
# On pr√©dit le r√©gime du lendemain pour chaque jour
predicted_next = []

for t in range(len(hidden_states) - 1):
    current_state = hidden_states[t]
    probs = model.transmat_[current_state]
    predicted_state = np.argmax(probs)
    predicted_next.append(predicted_state)

# D√©calage pour aligner avec les returns de t+1
predicted_next = [np.nan] + predicted_next  # Ajout d'un NaN pour que √ßa fasse la m√™me longueur
data['Predicted_Regime'] = predicted_next

# Strat√©gie : long uniquement si r√©gime pr√©dit = 0
data['Strategy_Returns'] = data['Log_Returns'] * (data['Predicted_Regime'] == 0)

# Cumul des rendements
data['Cumulative_Strategy'] = (1 + data['Strategy_Returns']).cumprod()
data['Cumulative_Market'] = (1 + data['Log_Returns']).cumprod()

# üìä Visualisation de la perf
plt.figure(figsize=(14, 6))
plt.plot(data.index, data['Cumulative_Market'], label='Buy & Hold (S&P500)', color='black', linestyle='--')
plt.plot(data.index, data['Cumulative_Strategy'], label='Strat√©gie HMM (long si r√©gime 0)', color='green')
plt.title("Performance cumul√©e : HMM vs Buy & Hold")
plt.ylabel("Capital (base 1)")
plt.xlabel("Date")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

perf = data[['Strategy_Returns', 'Log_Returns']].dropna()
mean_strategy = perf['Strategy_Returns'].mean() * 252
mean_market = perf['Log_Returns'].mean() * 252
vol_strategy = perf['Strategy_Returns'].std() * np.sqrt(252)
vol_market = perf['Log_Returns'].std() * np.sqrt(252)
sharpe_strategy = mean_strategy / vol_strategy
sharpe_market = mean_market / vol_market

print("üìä R√©sum√© des performances annualis√©es :")
print(f"Strat√©gie HMM : Rendement = {mean_strategy:.2%}, Volatilit√© = {vol_strategy:.2%}, Sharpe = {sharpe_strategy:.2f}")
print(f"Buy & Hold     : Rendement = {mean_market:.2%}, Volatilit√© = {vol_market:.2%}, Sharpe = {sharpe_market:.2f}")
# ‚úÖ Pr√©diction du r√©gime de demain pour chaque jour (multi-r√©gime)
predicted_next = []

for t in range(len(hidden_states) - 1):
    current_state = hidden_states[t]
    next_probs = model.transmat_[current_state]
    next_state_pred = np.argmax(next_probs)
    # Re-mappe selon l‚Äôordre tri√©
    next_state_remapped = remap[next_state_pred]
    predicted_next.append(next_state_remapped)

predicted_next = [np.nan] + predicted_next  # alignement temporel
data['Predicted_Regime'] = predicted_next

# ‚úÖ Signal de position : +1 = long (r√©gime 0), 0 = cash (r√©gime 1), -1 = short (r√©gime 2)
position = data['Predicted_Regime'].map({0: 1, 1: 0, 2: -1})
data['Position'] = position

# ‚úÖ Calcul des rendements de la strat√©gie
data['Strategy_Multi'] = data['Log_Returns'] * data['Position']
data['Cumulative_Multi'] = (1 + data['Strategy_Multi']).cumprod()
data['Cumulative_BH'] = (1 + data['Log_Returns']).cumprod()

# ‚úÖ Visualisation de la perf
plt.figure(figsize=(14, 6))
plt.plot(data.index, data['Cumulative_BH'], label='Buy & Hold (S&P 500)', linestyle='--', color='gray')
plt.plot(data.index, data['Cumulative_Multi'], label='Strat√©gie HMM multi-r√©gime', color='purple')
plt.title("Performance cumul√©e : strat√©gie multi-r√©gime HMM vs Buy & Hold")
plt.ylabel("Capital (base 1)")
plt.xlabel("Date")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ‚úÖ R√©sum√© des performances annualis√©es
perf = data[['Strategy_Multi', 'Log_Returns']].dropna()

mean_multi = perf['Strategy_Multi'].mean() * 252
vol_multi = perf['Strategy_Multi'].std() * np.sqrt(252)
sharpe_multi = mean_multi / vol_multi

mean_bh = perf['Log_Returns'].mean() * 252
vol_bh = perf['Log_Returns'].std() * np.sqrt(252)
sharpe_bh = mean_bh / vol_bh

print("\nüìä Performances annualis√©es :")
print(f"Strat√©gie Multi-r√©gime : Rendement = {mean_multi:.2%}, Volatilit√© = {vol_multi:.2f}, Sharpe = {sharpe_multi:.2f}")
print(f"Buy & Hold             : Rendement = {mean_bh:.2%}, Volatilit√© = {vol_bh:.2f}, Sharpe = {sharpe_bh:.2f}")
pip install streamlit yfinance hmmlearn matplotlib seaborn numpy pandas
SV HMM STATIC
# üì¶ Imports
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from sklearn.linear_model import LinearRegression
import seaborn as sns

# üì• 1. Donn√©es
data = yf.download('^GSPC', start='2000-01-01', end='2025-04-01')
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data.dropna(inplace=True)
returns = data['Log_Returns'].values.reshape(-1, 1)

# ü§ñ 2. HMM √† 3 r√©gimes + Viterbi
model = GaussianHMM(n_components=3, covariance_type='full', n_iter=1000)
model.fit(returns)
viterbi_states = model.predict(returns)  # Viterbi path

# üî¢ 3. Trier les r√©gimes par volatilit√©
variances = [np.var(returns[viterbi_states == i]) for i in range(3)]
sorted_states = np.argsort(variances)
remap = {old: new for new, old in enumerate(sorted_states)}
S_t = np.vectorize(remap.get)(viterbi_states)
data['Regime'] = S_t

# üìä 4. Pr√©parer log(R¬≤) pour estimer h_t
data['Log_R2'] = np.log(data['Log_Returns'] ** 2 + 1e-8)

# üîÅ 5. Estimation AR(1) par r√©gime
params = {}
h_t = np.zeros(len(data))

for state in range(3):
    idx = data['Regime'] == state
    h_obs = data['Log_R2'][idx].values
    h_lag = np.roll(h_obs, 1)
    h_obs = h_obs[1:]
    h_lag = h_lag[1:]

    model_ar = LinearRegression()
    model_ar.fit(h_lag.reshape(-1, 1), h_obs)
    phi = model_ar.coef_[0]
    mu = model_ar.intercept_ / (1 - phi)
    resid = h_obs - model_ar.predict(h_lag.reshape(-1, 1))
    sigma_eta = np.std(resid)

    params[state] = {'mu': mu, 'phi': phi, 'sigma_eta': sigma_eta}

    indices = np.where(data['Regime'] == state)[0]
    h_t[indices[0]] = mu
    for i in range(1, len(indices)):
        t = indices[i]
        t_prev = indices[i - 1]
        if t == t_prev + 1:
            h_t[t] = mu + phi * (h_t[t - 1] - mu)
        else:
            h_t[t] = mu

# üî¢ 6. Ajout de h_t et œÉ_t
data['h_t'] = h_t
data['Sigma_t'] = np.exp(h_t / 2)

# üìà 7. Volatilit√© implicite
plt.figure(figsize=(14, 5))
plt.plot(data.index, data['Sigma_t'] * np.sqrt(252), label='Vol. implicite annualis√©e')
plt.title("Volatilit√© implicite estim√©e (SV-HMM + Viterbi)")
plt.xlabel("Date")
plt.ylabel("Vol annualis√©e")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# üíº 8. Strat√©gie : long si r√©gime 0, cash si 1, short si 2
position = data['Regime'].map({0: 1, 1: 0, 2: -1})
data['Strategy_SV'] = data['Log_Returns'] * position
data['Cumulative_SV'] = (1 + data['Strategy_SV']).cumprod()
data['Cumulative_BH'] = (1 + data['Log_Returns']).cumprod()

# üìä 9. Visualisation de la performance
plt.figure(figsize=(14, 6))
plt.plot(data.index, data['Cumulative_BH'], label='Buy & Hold', linestyle='--', color='gray')
plt.plot(data.index, data['Cumulative_SV'], label='Strat√©gie SV-HMM + Viterbi', color='purple')
plt.title("Performance cumul√©e : strat√©gie SV-HMM (Viterbi) vs march√©")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# üìà 10. Performances
perf = data[['Strategy_SV', 'Log_Returns']].dropna()
mean_sv = perf['Strategy_SV'].mean() * 252
vol_sv = perf['Strategy_SV'].std() * np.sqrt(252)
sharpe_sv = mean_sv / vol_sv

mean_bh = perf['Log_Returns'].mean() * 252
vol_bh = perf['Log_Returns'].std() * np.sqrt(252)
sharpe_bh = mean_bh / vol_bh

print("üìä Performances annualis√©es :")
print(f"Strat√©gie SV-HMM : Rendement = {mean_sv:.2%}, Vol = {vol_sv:.2f}, Sharpe = {sharpe_sv:.2f}")
print(f"Buy & Hold      : Rendement = {mean_bh:.2%}, Vol = {vol_bh:.2f}, Sharpe = {sharpe_bh:.2f}")

# üìä 11. Matrice de transition tri√©e
mat_sorted = model.transmat_[sorted_states][:, sorted_states]
plt.figure(figsize=(4, 3))
sns.heatmap(mat_sorted, annot=True, cmap='Blues', fmt=".2f",
            xticklabels=[f"R√©gime {i}" for i in range(3)],
            yticklabels=[f"R√©gime {i}" for i in range(3)])
plt.title("üîÅ Matrice de transition (tri√©e)")
plt.tight_layout()
plt.show()

# üìä 12. Dur√©e moyenne par r√©gime
print("\n‚è±Ô∏è Dur√©e moyenne par r√©gime :")
for i in range(3):
    durations = data['Regime'].eq(i).astype(int).groupby((data['Regime'] != i).cumsum()).sum()
    print(f"R√©gime {i} : {durations.mean():.2f} jours")

# üìä 13. Statistiques par r√©gime
print("\nüìä Statistiques par r√©gime (log-returns) :")
for i in range(3):
    sub = data[data['Regime'] == i]
    mean = sub['Log_Returns'].mean()
    var = sub['Log_Returns'].var()
    ann_vol = np.sqrt(var) * np.sqrt(252)
    print(f"R√©gime {i} : Moyenne = {mean:.5f}, Variance = {var:.5f}, Vol. annualis√©e = {ann_vol:.2%}")

# üé® 14. Visualisation des r√©gimes
colors_map = {0: 'green', 1: 'orange', 2: 'red'}
plt.figure(figsize=(14, 6))
for i in range(3):
    mask = data['Regime'] == i
    plt.plot(data.index[mask], data['Log_Returns'][mask], '.', label=f"R√©gime {i}", color=colors_map[i], alpha=0.5)

plt.title("R√©gimes de march√© d√©tect√©s par SV-HMM (Viterbi)")
plt.xlabel("Date")
plt.ylabel("Log-returns")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm

# Param√®tres
rolling_window = 1000
refit_every = 10
positions = []
dates = []
returns_strategy = []

model_roll = None
viterbi_states = None
last_transmat = None
last_state = None
remap = None

# üìä Boucle principale
loop_range = range(rolling_window, len(data) - 1)
for t in tqdm(loop_range, desc="‚è≥ HMM semi-s√©quentiel √† 3 r√©gimes"):
    window_returns = returns[t - rolling_window:t]

    if (t - rolling_window) % refit_every == 0:
        try:
            if np.var(window_returns) < 1e-7:
                continue

            model_roll = GaussianHMM(n_components=3, covariance_type='full', n_iter=100)
            model_roll.fit(window_returns)
            viterbi_states = model_roll.predict(window_returns)

            vols = [np.var(window_returns[viterbi_states == i]) for i in range(3)]
            order = np.argsort(vols)
            remap = {old: new for new, old in enumerate(order)}
            viterbi_states = np.vectorize(remap.get)(viterbi_states)

            last_state = viterbi_states[-1]
            last_transmat = model_roll.transmat_[order][:, order]

        except:
            continue

    if model_roll is None or last_transmat is None:
        continue

    # üîÆ Pr√©diction du r√©gime de demain
    proba_next = last_transmat[last_state]
    pred_next_state = np.argmax(proba_next)
    last_state = pred_next_state

    # ‚úÖ Strat√©gie : long = 0, cash = 1, short = 2
    pos = {0: 1, 1: 0, 2: -1}[pred_next_state]
    r_tomorrow = data['Log_Returns'].iloc[t + 1]

    positions.append(pos)
    dates.append(data.index[t + 1])
    returns_strategy.append(pos * r_tomorrow)

# üìä R√©sultats
df_seq3 = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy
}).set_index('Date')

df_seq3['Cumulative_Strategy'] = (1 + df_seq3['Return_Strategy']).cumprod()
df_seq3['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df_seq3.index]).cumprod()

# üìà Courbe de performance
plt.figure(figsize=(14, 6))
plt.plot(df_seq3.index, df_seq3['Cumulative_Market'], label='Buy & Hold', linestyle='--', color='gray')
plt.plot(df_seq3.index, df_seq3['Cumulative_Strategy'], label='Strat√©gie HMM semi-s√©quentielle (3 r√©gimes)', color='darkblue')
plt.title("Performance cumul√©e : strat√©gie HMM semi-s√©quentielle (3 r√©gimes)")
plt.ylabel("Capital (base 1)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# üìä Statistiques
mean_seq3 = df_seq3['Return_Strategy'].mean() * 252
vol_seq3 = df_seq3['Return_Strategy'].std() * np.sqrt(252)
sharpe_seq3 = mean_seq3 / vol_seq3

print("\nüìä Performance HMM semi-s√©quentielle (3 r√©gimes) :")
print(f"Rendement annualis√© = {mean_seq3:.2%}")
print(f"Volatilit√© annualis√©e = {vol_seq3:.2%}")
print(f"Sharpe ratio = {sharpe_seq3:.2f}")
HMM basic Static
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm
import yfinance as yf

# üì• Donn√©es
data = yf.download('^GSPC', start='2000-01-01', end='2025-04-01')
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data.dropna(inplace=True)
returns = data['Log_Returns'].values.reshape(-1, 1)

# ‚öôÔ∏è Param√®tres
rolling_window = 500
refit_every = 5
positions = []
dates = []
returns_strategy = []
panic_flags = []

model_roll = None
viterbi_states = None
last_transmat = None
last_state = None
remap = None

# üîê Panic mode
panic_mode = False
panic_timer = 0

loop_range = range(rolling_window, len(data) - 1)
for t in tqdm(loop_range, desc="üö® HMM 4 r√©gimes + Real Panic Mode"):

    window_returns = returns[t - rolling_window:t]

    if (t - rolling_window) % refit_every == 0:
        try:
            model_roll = GaussianHMM(n_components=4, covariance_type='full', n_iter=1000)
            model_roll.fit(window_returns)
            viterbi_states = model_roll.predict(window_returns)

            vols = [np.var(window_returns[viterbi_states == i]) for i in range(4)]
            order = np.argsort(vols)
            remap = {old: new for new, old in enumerate(order)}
            viterbi_states = np.vectorize(remap.get)(viterbi_states)

            last_state = viterbi_states[-1]
            last_transmat = model_roll.transmat_[order][:, order]

        except:
            continue

    if model_roll is None or last_transmat is None:
        continue

    # üìâ Stats march√© r√©cents
    rolling_vol = np.std(returns[t-20:t]) * np.sqrt(252)
    recent_return = np.mean(returns[t-5:t])

    # üî• 1. Panic Mode d√©clenchement
    if not panic_mode and rolling_vol > 0.6 and recent_return < -0.01:
        panic_mode = True
        panic_timer = 30
        print(f"üõë Panic mode ACTIV√â le {data.index[t]}")

    # üîì 2. Panic Mode d√©sactivation
    elif panic_mode:
        if (rolling_vol < 0.3 and recent_return > 0) or panic_timer <= 0:
            panic_mode = False
            print(f"‚úÖ Panic mode D√âSACTIV√â le {data.index[t]}")
        else:
            panic_timer -= 1

    # üìà 3. Allocation
    if panic_mode:
        pos = 0  # üõë LOCK
        panic_flags.append(1)
    else:
        proba_next = last_transmat[last_state]
        pos = proba_next[0]*1 + proba_next[1]*0.5 + proba_next[2]*(-0.5) + proba_next[3]*(-1)
        last_state = np.argmax(proba_next)
        panic_flags.append(0)

    r_tomorrow = data['Log_Returns'].iloc[t + 1]
    positions.append(pos)
    dates.append(data.index[t + 1])
    returns_strategy.append(pos * r_tomorrow)

# üìä R√©sultats
df_panic = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Panic_Mode': panic_flags
}).set_index('Date')

df_panic['Cumulative_Strategy'] = (1 + df_panic['Return_Strategy']).cumprod()
df_panic['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df_panic.index]).cumprod()

# üìà Graphe perf + panic zones
plt.figure(figsize=(14, 6))
plt.plot(df_panic.index, df_panic['Cumulative_Market'], label='Buy & Hold', linestyle='--', color='gray')
plt.plot(df_panic.index, df_panic['Cumulative_Strategy'], label='Strat√©gie HMM pond√©r√©e + Panic Mode', color='darkred')

# Barres rouges pour panic
for i in range(len(df_panic)):
    if df_panic['Panic_Mode'].iloc[i] == 1:
        plt.axvline(df_panic.index[i], color='red', alpha=0.02)

plt.title("Performance strat√©gie HMM pond√©r√©e √† 4 r√©gimes + Panic Mode")
plt.ylabel("Capital (base 1)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# üìä Statistiques
mean = df_panic['Return_Strategy'].mean() * 252
vol = df_panic['Return_Strategy'].std() * np.sqrt(252)

print("\nüìä R√©sultats finaux :")
print(f"Rendement annualis√© : {mean:.2%}")
print(f"Volatilit√© annualis√©e : {vol:.2%}")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
import yfinance as yf

# üì• Donn√©es
data = yf.download('^GSPC', start='2000-01-01', end='2025-04-01')
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data.dropna(inplace=True)
returns = data['Log_Returns'].values.reshape(-1, 1)

# üîÅ Comparaison pour diff√©rents nombres d'√©tats
log_likelihoods = []
aics = []
bics = []
K_range = range(1, 6)
n_obs = len(returns)

for k in K_range:
    try:
        model = GaussianHMM(n_components=k, covariance_type='full', n_iter=1000, random_state=42)
        model.fit(returns)
        log_likelihood = model.score(returns)

        # ‚öôÔ∏è Nombre de param√®tres :
        # (k-1) pour startprob, k(k-1) pour transmat, k pour variances, k pour moyennes
        n_params = (k - 1) + (k * (k - 1)) + k + k

        aic = -2 * log_likelihood + 2 * n_params
        bic = -2 * log_likelihood + n_params * np.log(n_obs)

        log_likelihoods.append(log_likelihood)
        aics.append(aic)
        bics.append(bic)

    except Exception as e:
        print(f"Erreur pour {k} √©tats : {e}")
        log_likelihoods.append(np.nan)
        aics.append(np.nan)
        bics.append(np.nan)

# üìà Graphe comparatif
# üìä Replot en 2 graphes pour meilleure lisibilit√©
fig, ax = plt.subplots(2, 1, figsize=(10, 10), sharex=True)

# Graph 1 : log-vraisemblance
ax[0].plot(K_range, log_likelihoods, marker='o', color='blue')
ax[0].set_title("Log-vraisemblance selon le nombre d'√©tats")
ax[0].set_ylabel("Log-likelihood")
ax[0].grid(True)

# Graph 2 : AIC / BIC
ax[1].plot(K_range, aics, marker='s', label='AIC', color='orange')
ax[1].plot(K_range, bics, marker='^', label='BIC', color='green')
ax[1].set_title("AIC et BIC selon le nombre d'√©tats")
ax[1].set_xlabel("Nombre d'√©tats")
ax[1].set_ylabel("Score")
ax[1].legend()
ax[1].grid(True)

plt.tight_layout()
plt.show()

# ‚úÖ Meilleur mod√®le selon BIC
best_k = K_range[np.nanargmin(bics)]
print(f"\n‚úÖ Nombre optimal d'√©tats selon le BIC : {best_k}")
# Param√®tres √† tester
window_sizes = [250, 500, 750, 1000, 1250]
sharpe_scores = []

for rw in tqdm(window_sizes, desc="üîç Optimisation de la fen√™tre"):

    model = None
    positions = []
    returns_strategy = []
    last_transmat = None
    last_state = None

    for t in range(rw, len(returns) - 1):
        window_returns = returns[t - rw:t]

        # R√©estimation tous les 20 jours
        if (t - rw) % 20 == 0:
            try:
                model = GaussianHMM(n_components=3, covariance_type='full', n_iter=100)
                model.fit(window_returns)
                viterbi = model.predict(window_returns)
                vols = [np.var(window_returns[viterbi == i]) for i in range(3)]
                order = np.argsort(vols)
                last_transmat = model.transmat_[order][:, order]
                last_state = order.tolist().index(viterbi[-1])
            except:
                continue

        if model is None or last_transmat is None:
            continue

        # Pr√©diction du r√©gime de demain
        p_next = last_transmat[last_state]
        pos = p_next[0]*1 + p_next[1]*0 + p_next[2]*(-1)
        last_state = np.argmax(p_next)

        r_tomorrow = data['Log_Returns'].iloc[t + 1]
        returns_strategy.append(pos * r_tomorrow)
        positions.append(pos)

    # Calcul du Sharpe
    strat = pd.Series(returns_strategy)
    sharpe = strat.mean() * 252 / (strat.std() * np.sqrt(252))
    sharpe_scores.append(sharpe)

# üîç R√©sultats
df_opt = pd.DataFrame({'Rolling_Window': window_sizes, 'Sharpe': sharpe_scores})

plt.figure(figsize=(10, 5))
plt.plot(df_opt['Rolling_Window'], df_opt['Sharpe'], marker='o')
plt.title("Sharpe ratio en fonction de la taille de la fen√™tre")
plt.xlabel("Taille de la rolling window (jours)")
plt.ylabel("Sharpe ratio annualis√©")
plt.grid(True)
plt.tight_layout()
plt.show()

best_rw = df_opt.loc[df_opt['Sharpe'].idxmax(), 'Rolling_Window']
print(f"üèÜ Meilleure taille de rolling window : {int(best_rw)} jours")
HMM test Static
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm
import yfinance as yf

# üì• Donn√©es
data = yf.download('^GSPC', start='2000-01-01', end='2025-04-01')
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data.dropna(inplace=True)
returns = data['Log_Returns'].values.reshape(-1, 1)

# ‚öôÔ∏è Param√®tres
rolling_window = 500
refit_every = 3
n_states = 4

positions = []
dates = []
returns_strategy = []
panic_flags = []

model = None
remap = None
last_state = None
last_transmat = None

# Panic mode
panic_mode = False
panic_timer = 0

# üîÅ Boucle principale
for t in tqdm(range(rolling_window, len(returns) - 1), desc="üìä HMM 4 r√©gimes + Panic Mode"):

    window_returns = returns[t - rolling_window:t]

    if (t - rolling_window) % refit_every == 0:
        try:
            model = GaussianHMM(n_components=n_states, covariance_type='full', n_iter=100)
            model.fit(window_returns)

            if np.any(model.transmat_.sum(axis=1) == 0):
                continue

            viterbi = model.predict(window_returns)
            vols = [np.var(window_returns[viterbi == i]) for i in range(n_states)]
            order = np.argsort(vols)
            remap = {old: new for new, old in enumerate(order)}
            last_state = remap[viterbi[-1]]
            last_transmat = model.transmat_[order][:, order]
        except:
            continue

    if model is None or last_transmat is None:
        continue

    # üîç Analyse march√© r√©cente
    rolling_vol = np.std(returns[t-20:t]) * np.sqrt(252)
    recent_return = np.mean(returns[t-5:t])

    # üî• Panic Mode d√©clenchement
    if not panic_mode and rolling_vol > 0.6 and recent_return < -0.01:
        panic_mode = True
        panic_timer = 30
        print(f"üõë Panic mode ACTIV√â le {data.index[t]}")

    # üîì D√©sactivation
    elif panic_mode:
        if (rolling_vol < 0.3 and recent_return > 0) or panic_timer <= 0:
            panic_mode = False
            print(f"‚úÖ Panic mode D√âSACTIV√â le {data.index[t]}")
        else:
            panic_timer -= 1

    # ‚öñÔ∏è Position
    if panic_mode:
        pos = 0  # üõë full cash
        panic_flags.append(1)
    else:
        proba_next = last_transmat[last_state]
        pos = proba_next[0]*1 + proba_next[1]*0.5 + proba_next[2]*(-0.5) + proba_next[3]*(-1)
        last_state = np.argmax(proba_next)
        panic_flags.append(0)

    r_tomorrow = data['Log_Returns'].iloc[t + 1]
    returns_strategy.append(pos * r_tomorrow)
    positions.append(pos)
    dates.append(data.index[t + 1])

# üìä R√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Panic_Mode': panic_flags
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# üìà Graphe de perf + panic zone
plt.figure(figsize=(14, 6))
plt.plot(df.index, df['Cumulative_Market'], linestyle='--', color='gray', label='Buy & Hold')
plt.plot(df.index, df['Cumulative_Strategy'], color='brown', label='Strat√©gie HMM pond√©r√©e + Panic Mode')

for i in range(len(df)):
    if df['Panic_Mode'].iloc[i] == 1:
        plt.axvline(df.index[i], color='red', alpha=0.02)

plt.title("Strat√©gie HMM pond√©r√©e (4 r√©gimes) + Panic Mode")
plt.ylabel("Capital (base 1)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# üìä Statistiques finales
mean = df['Return_Strategy'].mean() * 252
vol = df['Return_Strategy'].std() * np.sqrt(252)

print("\nüìä R√©sultats finaux :")
print(f"Rendement annualis√© : {mean:.2%}")

print(f"Volatilit√© annualis√©e : {vol:.2f}")
benchmark ma100
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# T√©l√©charger les donn√©es BTC-USD (ou tout autre actif)
data = yf.download('BTC-USD', start='2014-01-01', end='2025-01-01')
# Calculer les log-returns
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
# Calculer la moyenne mobile sur 100 jours (MA100)
data['MA100'] = data['Close'].rolling(100).mean()
data.dropna(inplace=True)

# G√©n√©rer le signal simple bas√© sur MA100
positions = []
dates = []
returns_strategy = []

for t in range(len(data) - 1):
    # Forcer la conversion en float pour √©viter l'ambigu√Øt√©
    current_close = float(data['Close'].iloc[t])
    current_MA100 = float(data['MA100'].iloc[t])
    # Signal binaire simple : long si Close > MA100, sinon short
    if current_close > current_MA100:
        position = 1
    else:
        position = -1
    # Appliquer la position au retour du lendemain
    r_tomorrow = data['Log_Returns'].iloc[t + 1]
    positions.append(position)
    dates.append(data.index[t + 1])
    returns_strategy.append(position * r_tomorrow)

# Construire le DataFrame des r√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# Graphique comparatif
plt.figure(figsize=(14,6))
plt.plot(df.index, df['Cumulative_Market'], '--', label='Buy & Hold', color='gray')
plt.plot(df.index, df['Cumulative_Strategy'], label='MA100 Strategy', color='red')
plt.title("Performance : Buy & Hold vs MA100 Strategy")
plt.ylabel("Capital cumul√© (base 1)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# Calcul des statistiques de performance
mean = df['Return_Strategy'].mean() * 252
vol = df['Return_Strategy'].std() * np.sqrt(252)
sharpe = mean / vol

print("Performance MA100 Strategy :")
print(f"Rendement annualis√© = {mean:.2%}")
print(f"Volatilit√© annualis√©e = {vol:.2%}")
print(f"Sharpe Ratio = {sharpe:.2f}")
HMM V1
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm

# 1. T√©l√©charger les donn√©es du SP500 (ici '^GSPC')
data = yf.download('ETH-USD', start='2014-01-01', end='2025-01-01')
# Utilisation du "Close" pour ce code
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
# Calcul de la MA100 pour le filtre de tendance (MA100)
data['MA100'] = data['Close'].rolling(100).mean()
data.dropna(inplace=True)
log_returns = data['Log_Returns'].values

# 2. Param√®tres du rolling
window = 300    # Fen√™tre pour capter rapidement la dynamique
refit_every = 10  # R√©estimation plus fr√©quente
positions, dates, returns_strategy = [], [], []
regime_list = []

for t in tqdm(range(window, len(data) - 1), desc="Rolling HMM Simple √† 4 √©tats"):
    if (t - window) % refit_every != 0:
        continue

    window_returns = log_returns[t - window:t].reshape(-1, 1)
    model = GaussianHMM(n_components=4, covariance_type='full', n_iter=300)
    
    try:
        if np.var(window_returns) < 1e-8:
            continue
        model.fit(window_returns)
        if not np.allclose(model.transmat_.sum(axis=1), 1):
            continue
        if not np.all(np.isfinite(model.covars_)):
            continue
    except:
        continue

    # D√©codeur Viterbi pour obtenir la s√©quence d'√©tats sur la fen√™tre
    viterbi_states = model.predict(window_returns)
    
    # Reclassification : trier les √©tats selon leur volatilit√© via la trace des covariances 
    # (on consid√®re 0 = √©tat le moins volatil et 3 = √©tat le plus volatil)
    if model.covars_.ndim == 3:
        vols = [np.trace(model.covars_[i]) for i in range(4)]
    else:
        vols = model.covars_.flatten()
    sorted_idx = np.argsort(vols)  
    remap = {old: new for new, old in enumerate(sorted_idx)}
    
    # On r√©cup√®re l'√©tat du dernier jour de la fen√™tre et on le reclasse
    last_state_original = viterbi_states[-1]
    last_state_reclassified = remap[last_state_original]
    
    # D√©finition du signal selon l'√©tat reclass√© :
    # Nous d√©finissons une √©chelle continue sur 4 √©tats :
    # √©tat 0 (calme)   -> signal = +1
    # √©tat 1 (interm√©diaire) -> signal = +0.5
    # √©tat 2 (interm√©diaire) -> signal = -0.5
    # √©tat 3 (panique) -> signal = -1
    if last_state_reclassified == 0:
        signal = 1.0
    elif last_state_reclassified == 1:
        signal = 0.5
    elif last_state_reclassified == 2:
        signal = -0.5
    elif last_state_reclassified == 3:
        signal = -1.0
    else:
        signal = 0

    # Filtre de tendance : si le prix actuel est inf√©rieur ou √©gal √† la MA100, on neutralise le signal
    current_close = float(data['Close'].iloc[t])
    current_MA100 = float(data['MA100'].iloc[t])
    if current_close <= current_MA100:
        signal = 0

    r_tomorrow = log_returns[t + 1]
    positions.append(signal)
    dates.append(data.index[t + 1])
    returns_strategy.append(signal * r_tomorrow)
    regime_list.append(last_state_reclassified)

# 3. Construction du DataFrame des r√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Regime': regime_list
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# 4. Graphique comparatif avec affichage de la MA100
fig, ax1 = plt.subplots(figsize=(14,6))
ax1.plot(df.index, df['Cumulative_Market'], '--', label='Buy & Hold', color='gray')
ax1.plot(df.index, df['Cumulative_Strategy'], label='HMM Simple Strategy √† 4 √©tats', color='red')
ax1.set_ylabel("Capital cumul√© (base 1)")
ax1.grid(True)
ax1.legend(loc='upper left')

# Axe secondaire pour afficher la MA100
ax2 = ax1.twinx()
ax2.plot(data.index, data['MA100'], label='MA100', color='blue', alpha=0.4)
ax2.set_ylabel("MA100")
ax2.legend(loc='upper right')

plt.title("Performance : Buy & Hold vs HMM Simple (4 √©tats, avec MA100)")
plt.tight_layout()
plt.show()

# 5. Statistiques finales
mean_simple = df['Return_Strategy'].mean() * 252
vol_simple = df['Return_Strategy'].std() * np.sqrt(252)
sharpe_simple = mean_simple / vol_simple

print("Performance HMM Simple √† 4 √©tats sur BTC-USD :")
print(f"Rendement annualis√© = {mean_simple:.2%}")
print(f"Volatilit√© annualis√©e = {vol_simple:.2%}")
print(f"Sharpe Ratio = {sharpe_simple:.2f}")
V3
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm
from sklearn.linear_model import LinearRegression

# 1. T√©l√©charger les donn√©es BTC-USD (Bitcoin)
data = yf.download('CL=F', start='2004-01-01', end='2025-01-01')
# Utilisation du "Close" pour ce code
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
# Calcul de la moyenne mobile sur 100 jours pour le filtre de tendance (MA100)
data['MA100'] = data['Close'].rolling(100).mean()
data.dropna(inplace=True)
log_returns = data['Log_Returns'].values

# 2. Param√®tres du rolling
window = 300    # Fen√™tre plus courte pour capter rapidement la dynamique
refit_every = 10  # R√©estimation plus fr√©quente pour suivre les changements
positions, dates, returns_strategy = [], [], []
regimes_rolling = []

# Boucle rolling sur les donn√©es
for t in tqdm(range(window, len(data) - 1), desc="Rolling HMMSV sur BTC-USD"):
    
    if (t - window) % refit_every != 0:
        continue
    
    window_returns = log_returns[t - window:t].reshape(-1, 1)
    model = GaussianHMM(n_components=3, covariance_type='full', n_iter=300)
    
    try:
        if np.var(window_returns) < 1e-8:
            continue
        model.fit(window_returns)
        if not np.allclose(model.transmat_.sum(axis=1), 1):
            continue
        if not np.all(np.isfinite(model.covars_)):
            continue
    except:
        continue

    # Obtenir les probabilit√©s d'√©tat sur la fen√™tre et retenir celle du dernier jour
    proba = model.predict_proba(window_returns)
    last_proba = proba[-1]
    
    # Reclasser dynamiquement les √©tats en fonction de la volatilit√© (trace des covariances)
    if model.covars_.ndim == 3:
        vols = [np.trace(model.covars_[i]) for i in range(3)]
    else:
        vols = model.covars_.flatten()
    sorted_idx = np.argsort(vols)  # On suppose : 0 = √©tat de faible volatilit√© (calme), 2 = √©tat de forte volatilit√© (panique)
    remap = {old: new for new, old in enumerate(sorted_idx)}
    reordered_proba = np.zeros(3)
    for i in range(3):
        reordered_proba[remap[i]] = last_proba[i]
    
    # -------------------------
    # Ajout de la mod√©lisation AR(1) pour une dynamique de volatilit√© (HMMSV)
    #
    # On estime pour chaque √©tat i un AR(1) sur log(R¬≤) dans la fen√™tre.
    # On utilise une condition sur la probabilit√© (par exemple, proba > 0.5) pour s√©lectionner les p√©riodes appartenant √† cet √©tat.
    log_r2 = np.log(window_returns.flatten()**2 + 1e-8)
    sigma_states = np.zeros(3)
    for i in range(3):
        idx = np.where(proba[:, i] > 0.5)[0]
        if len(idx) < 3:
            sigma_states[i] = np.nan
        else:
            y_ar = log_r2[idx]
            x_ar = np.roll(y_ar, 1)[1:]
            y_ar_fit = y_ar[1:]
            model_ar = LinearRegression().fit(x_ar.reshape(-1, 1), y_ar_fit)
            phi = model_ar.coef_[0]
            mu = model_ar.intercept_ / (1 - phi)
            h_ar = np.zeros(len(idx))
            h_ar[0] = mu
            for j in range(1, len(idx)):
                # Si les indices sont cons√©cutifs, on propage via AR(1), sinon on r√©initialise
                if idx[j] == idx[j-1] + 1:
                    h_ar[j] = mu + phi * (h_ar[j-1] - mu)
                else:
                    h_ar[j] = mu
            sigma_states[i] = np.exp(h_ar[-1] / 2)  # Volatilit√© pr√©visionnelle pour cet √©tat

    # Calcul de la volatilit√© globale pr√©visionnelle comme moyenne pond√©r√©e des sigma_states,
    # en utilisant les probabilit√©s reclass√©es (si certaines valeurs sont NaN, on les ignore)
    valid = ~np.isnan(sigma_states)
    if np.sum(valid) > 0:
        sigma_weighted = np.sum(reordered_proba[valid]*sigma_states[valid]) / np.sum(reordered_proba[valid])
    else:
        sigma_weighted = 0.02  # valeur par d√©faut

    # -------------------------
    # Filtre de tendance : comparer le Close et le MA100 (conversion en float)
    current_close = float(data['Close'].iloc[t])
    current_MA100 = float(data['MA100'].iloc[t])
    if current_close > current_MA100:
        # Tendance haussi√®re : booster l'exposition long et att√©nuer le short
        long_weight = 2.0
        short_weight = -0.25
    else:
        # Tendance baissi√®re : r√©duire l'exposition long et rester agressif short
        long_weight = 0.75
        short_weight = -1.0

    # Signal issu du HMM de base (pond√©r√©) :
    hmm_signal = reordered_proba[0] * long_weight + reordered_proba[2] * short_weight
    # Optionnellement, on peut moduler le signal en fonction de la volatilit√© pr√©visionnelle.
    # Par exemple, si la volatilit√© pr√©visionnelle est trop √©lev√©e, r√©duire l'exposition.
    threshold = 0.03  # Par exemple, 3% de volatilit√© journalier attendue
    if sigma_weighted > threshold:
        final_signal = hmm_signal * 0.5  # r√©duction de l'exposition si vol trop √©lev√©e
    else:
        final_signal = hmm_signal

    # -------------------------
    r_tomorrow = log_returns[t + 1]
    positions.append(final_signal)
    dates.append(data.index[t + 1])
    returns_strategy.append(final_signal * r_tomorrow)
    regimes_rolling.append(np.argmax(reordered_proba))

# 3. Construction du DataFrame des r√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Regime': regimes_rolling
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# 4. Graphique comparatif avec affichage de la MA100
fig, ax1 = plt.subplots(figsize=(14,6))
ax1.plot(df.index, df['Cumulative_Market'], '--', label='Buy & Hold', color='gray')
ax1.plot(df.index, df['Cumulative_Strategy'], label='HMMSV optimis√©', color='blue')
ax1.set_ylabel("Capital cumul√© (base 1)")
ax1.grid(True)
ax1.legend(loc='upper left')

# Axe secondaire pour afficher la MA100
ax2 = ax1.twinx()
ax2.plot(data.index, data['MA100'], label='MA100', color='orange', alpha=0.5)
ax2.set_ylabel("MA100")
ax2.legend(loc='upper right')

plt.title("Performance : Buy & Hold vs HMMSV sur BTC-USD (avec MA100)")
plt.tight_layout()
plt.show()

# 5. Statistiques finales
mean = df['Return_Strategy'].mean() * 252
vol = df['Return_Strategy'].std() * np.sqrt(252)
sharpe = mean / vol

print("Approximate SV-HMM with rolling volatility-adjusted HMM probabilities and AR(1)-based volatility forecast")
print(f"Rendement annualis√© = {mean:.2%}")
print(f"Volatilit√© annualis√©e = {vol:.2%}")
print(f"Sharpe Ratio = {sharpe:.2f}")
print(f"Volatilit√© pr√©visionnelle (moyenne pond√©r√©e) = {sigma_weighted:.4f}")
V3 MODIF
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm

# 1. T√©l√©charger les donn√©es du SP500 (ici '^GSPC')
data = yf.download('CL=F', start='2014-01-01', end='2025-01-01')
# Utilisation du "Close" pour ce code
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
# Calcul de la MA100 pour le filtre de tendance (MA100)
data['MA100'] = data['Close'].rolling(100).mean()
data.dropna(inplace=True)
log_returns = data['Log_Returns'].values

# 2. Param√®tres du rolling
window = 300   # Fen√™tre pour capter rapidement la dynamique
refit_every = 10  # R√©estimation plus fr√©quente
positions, dates, returns_strategy, regime_list = [], [], [], []

# Param√®tres pour la modulation de volatilit√©
vol_threshold = 0.03         # Seuil de volatilit√© attendu (exemple: 3% de volatilit√© journali√®re)
modulation_factor = 0.5      # Facteur de r√©duction de signal si volatilit√© trop forte
epsilon = 1e-8               # Petite constante pour √©viter log(0)

for t in tqdm(range(window, len(data)-1), desc="Rolling HMMSV avec filtre MA100"):
    if (t - window) % refit_every != 0:
        continue

    # Extraction de la fen√™tre d'observations
    window_returns = log_returns[t-window:t].reshape(-1, 1)
    
    # Ajustement de l'HMM (ici avec 3 √©tats)
    model = GaussianHMM(n_components=3, covariance_type='full', n_iter=300)
    try:
        if np.var(window_returns) < 1e-8:
            continue
        model.fit(window_returns)
        if not np.allclose(model.transmat_.sum(axis=1), 1):
            continue
        if not np.all(np.isfinite(model.covars_)):
            continue
    except:
        continue
    
    # Extraction des probabilit√©s d'appartenance via predict_proba
    proba = model.predict_proba(window_returns)
    last_proba = proba[-1]
    
    # Reclassification des √©tats en fonction de la volatilit√©
    if model.covars_.ndim == 3:
        vols = [np.trace(model.covars_[i]) for i in range(3)]
    else:
        vols = model.covars_.flatten()
    sorted_idx = np.argsort(vols)  # ordre croissant: 0 = √©tat le moins volatil, 2 = √©tat le plus volatil
    remap = {old: new for new, old in enumerate(sorted_idx)}
    reordered_proba = np.zeros(3)
    for i in range(3):
        reordered_proba[remap[i]] = last_proba[i]
    
    # Construction du signal de base √† partir des probabilit√©s
    # On assume que :
    # - l'√©tat 0 correspond √† un r√©gime "calme" (signal haussier),
    # - l'√©tat 2 correspond √† un r√©gime "panique" (signal baissier),
    # et on ignore l'√©tat interm√©diaire (signal pond√©r√© par 0).
    # Le choix des poids d√©pend de la tendance du march√© observ√©e.
    current_close = float(data['Close'].iloc[t])
    current_MA100 = float(data['MA100'].iloc[t])
    if current_close > current_MA100:
        w_long = 2.0
        w_short = -0.25
    else:
        w_long = 0.75
        w_short = -1.0
    signal_base = reordered_proba[0]*w_long + reordered_proba[2]*w_short
    
    # Estimation dynamique de la volatilit√© par un mod√®le AR(1) sur log(r^2)
    log_sq = np.log(window_returns**2 + epsilon)
    # Construction des paires (lag 1) pour ajuster y_t = phi * y_{t-1} + c
    X = log_sq[:-1].flatten()
    Y = log_sq[1:].flatten()
    try:
        phi, c = np.polyfit(X, Y, 1)
    except:
        continue
    h_last = log_sq[-1, 0]
    sigma_forecast = np.exp(h_last/2)
    
    # Modulation du signal par la volatilit√© pr√©vue
    if sigma_forecast > vol_threshold:
        signal_modulated = signal_base * modulation_factor
    else:
        signal_modulated = signal_base
    
    # Application du filtre MA100: si le prix actuel est inf√©rieur ou √©gal √† la MA100, 
    # on neutralise le signal
    if current_close <= current_MA100:
        signal_final = 0
    else:
        signal_final = signal_modulated
    
    # Calcul du rendement du jour suivant et enregistrement du signal
    r_tomorrow = log_returns[t+1]
    positions.append(signal_final)
    dates.append(data.index[t+1])
    returns_strategy.append(signal_final * r_tomorrow)
    regime_list.append(np.argmax(reordered_proba))

# 3. Construction du DataFrame des r√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Regime': regime_list
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# 4. Graphique comparatif avec affichage de la MA100
fig, ax1 = plt.subplots(figsize=(14,6))
ax1.plot(df.index, df['Cumulative_Market'], '--', label='Buy & Hold', color='gray')
ax1.plot(df.index, df['Cumulative_Strategy'], label='HMMSV Optimis√© avec MA100', color='blue')
ax1.set_ylabel("Capital cumul√© (base 1)")
ax1.grid(True)
ax1.legend(loc='upper left')

ax2 = ax1.twinx()
ax2.plot(data.index, data['MA100'], label='MA100', color='orange', alpha=0.5)
ax2.set_ylabel("MA100")
ax2.legend(loc='upper right')

plt.title("Performance : Buy & Hold vs HMMSV Optimis√© (avec MA100)")
plt.tight_layout()
plt.show()

# 5. Statistiques finales
mean_model3 = np.mean(df['Return_Strategy']) * 252
vol_model3 = np.std(df['Return_Strategy']) * np.sqrt(252)
sharpe_model3 = mean_model3 / vol_model3

print("Performance HMMSV Optimis√© avec MA100 sur BTC-USD :")
print(f"Rendement annualis√© = {mean_model3:.2%}")
print(f"Volatilit√© annualis√©e = {vol_model3:.2%}")
print(f"Sharpe Ratio = {sharpe_model3:.2f}")
V2
print("Shape du DataFrame :", data.shape)
print(data.head())
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm

# 1. Chargement des donn√©es depuis fichier local (Stooq)
data = pd.read_csv("/Users/jeremy.duriez/Desktop/^spx_d.csv")
data = data[::-1]
data = data.rename(columns=str.strip)
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)
data = data[data.index >= '2000-01-01']

# 2. Calcul des log-returns et MA100
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data['MA100'] = data['Close'].rolling(100).mean()
data.dropna(inplace=True)
log_returns = data['Log_Returns'].values

# 3. Param√®tres de la strat√©gie
window = 1000
refit_every = 30
positions, dates, returns_strategy, regime_list = [], [], [], []

for t in tqdm(range(window, len(data) - 1), desc="Rolling HMM Optimis√©"):
    if (t - window) % refit_every != 0:
        continue

    window_returns = log_returns[t - window:t].reshape(-1, 1)
    model = GaussianHMM(n_components=4, covariance_type='full', n_iter=500)

    try:
        if np.var(window_returns) < 1e-8:
            continue
        model.fit(window_returns)
        if not np.allclose(model.transmat_.sum(axis=1), 1):
            continue
        if not np.all(np.isfinite(model.covars_)):
            continue
    except:
        continue

    proba = model.predict_proba(window_returns)
    last_proba = proba[-1]

    # Reclassement des r√©gimes selon la volatilit√©
    if model.covars_.ndim == 3:
        vols = [np.trace(model.covars_[i]) for i in range(4)]
    else:
        vols = model.covars_.flatten()
    sorted_idx = np.argsort(vols)
    remap = {old: new for new, old in enumerate(sorted_idx)}

    reordered_proba = np.zeros(4)
    for i in range(4):
        reordered_proba[remap[i]] = last_proba[i]

    # Signal pond√©r√© par proba et r√©gimes
    signal_continuous = (
        +1.0 * reordered_proba[0] +
        +0.5 * reordered_proba[1] +
        -0.5 * reordered_proba[2] +
        -1.0 * reordered_proba[3]
    )

    # Ajustement selon la tendance (MA100)
    current_close = float(data['Close'].iloc[t])
    current_MA100 = float(data['MA100'].iloc[t])
    if current_close > current_MA100:
        signal_final = signal_continuous * 1.2
    else:
        signal_final = signal_continuous * 0.7

    # Ajustement selon la volatilit√© r√©cente (risk control)
    recent_vol = np.std(log_returns[t - 20:t])
    if recent_vol > 0.02:
        signal_final *= 0.5

    r_tomorrow = log_returns[t + 1]
    positions.append(signal_final)
    dates.append(data.index[t + 1])
    returns_strategy.append(signal_final * r_tomorrow)
    regime_list.append(np.argmax(reordered_proba))

# 4. R√©sultats
df = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Regime': regime_list
}).set_index('Date')

df['Cumulative_Strategy'] = (1 + df['Return_Strategy']).cumprod()
df['Cumulative_Market'] = (1 + data['Log_Returns'].loc[df.index]).cumprod()

# 5. Visualisation
fig, ax1 = plt.subplots(figsize=(14,6))
ax1.plot(df.index, df['Cumulative_Market'], '--', label='Buy & Hold (S&P 500)', color='gray')
ax1.plot(df.index, df['Cumulative_Strategy'], label='HMM Optimis√© (4 √©tats)', color='red')
ax1.set_ylabel("Capital cumul√© (base 1)")
ax1.grid(True)
ax1.legend(loc='upper left')

ax2 = ax1.twinx()
ax2.plot(data.index, data['MA100'], label='MA100', color='blue', alpha=0.4)
ax2.set_ylabel("MA100")
ax2.legend(loc='upper right')

plt.title("Performance : Buy & Hold vs HMM Optimis√© (S&P 500, 4 √©tats, MA100, scaling dynamique)")
plt.tight_layout()
plt.show()

# 6. Statistiques
mean = df['Return_Strategy'].mean() * 252
vol = df['Return_Strategy'].std() * np.sqrt(252)
sharpe = mean / vol
drawdown = (df['Cumulative_Strategy'] / df['Cumulative_Strategy'].cummax() - 1).min()

print("üìä Performance HMM Optimis√© sur S&P 500 :")
print(f"Rendement annualis√© = {mean:.2%}")
print(f"Volatilit√© annualis√©e = {vol:.2%}")
print(f"Sharpe Ratio = {sharpe:.2f}")
print(f"Max Drawdown = {drawdown:.2%}")
SVHMM volatility forecast
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hmmlearn.hmm import GaussianHMM
from tqdm import tqdm
from sklearn.linear_model import LinearRegression

# --- Step 0: reproducible jitter
rng = np.random.default_rng(42)
jitter_scale = 1e-8

# --- Step 1: Download data, compute returns & shifted MA100
data = yf.download('AAPL', start='2004-01-01', end='2025-01-01')
data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data['MA100']       = data['Close'].shift(1).rolling(100).mean()
data.dropna(inplace=True)

log_returns = data['Log_Returns'].values

# --- Step 2: Parameters
window           = 300
refit_every      = 10
transaction_cost = 0.001   # 0.1% round‚Äëtrip cost

# Storage
positions        = []
dates            = []
returns_strategy = []
regimes_rolling  = []

# State carried between refits
current_signal   = 0.0
current_regime   = 1
current_sigma    = 0.0

# --- Step 3: Rolling window, daily P&L
for t in tqdm(range(window, len(data) - 1), desc="Rolling SV‚ÄëHMM"):
    # only refit every refit_every days
    if (t - window) % refit_every == 0:
        window_ret = log_returns[t-window:t].reshape(-1,1)
        if np.var(window_ret) < 1e-8:
            # too little variance, skip
            pass
        else:
            try:
                # add tiny noise to avoid degenerate covariances
                wr = window_ret + rng.normal(0, jitter_scale, window_ret.shape)

                # fit HMM
                model = GaussianHMM(n_components=3, covariance_type='full', n_iter=300)
                model.fit(wr)

                # posterior probs
                proba      = model.predict_proba(wr)
                last_proba = proba[-1]

                # reorder by vol
                vols       = [np.trace(cov) for cov in model.covars_]
                order      = np.argsort(vols)
                p_reord    = np.array([ last_proba[i] for i in order ])

                # AR(1) on log‚Äêsq‚Äêreturns to forecast sigma per state
                lr2 = np.log(wr.flatten()**2 + 1e-8)
                sigma_states = np.zeros(3)
                for i in range(3):
                    idx = np.where(proba[:,i] > 0.5)[0]
                    if len(idx) >= 5:
                        y  = lr2[idx]
                        x  = y[:-1]; y1 = y[1:]
                        ar = LinearRegression().fit(x.reshape(-1,1), y1)
                        phi = ar.coef_[0]
                        if abs(phi) < 1:
                            mu = ar.intercept_/(1-phi)
                            h  = mu + phi*(y1[-1] - mu)
                            sigma_states[i] = np.exp(h/2)
                        else:
                            sigma_states[i] = np.nan
                    else:
                        sigma_states[i] = np.nan

                valid = ~np.isnan(sigma_states)
                if valid.any():
                    current_sigma = (p_reord[valid]*sigma_states[valid]).sum() / p_reord[valid].sum()

                # trend filter via shifted MA100
                price = float(data['Close'].iloc[t])
                ma100 = float(data['MA100'].iloc[t])
                if price > ma100:
                    lw, sw = 2.0, -0.25
                else:
                    lw, sw = 0.75, -1.0

                # build signal
                hmm_sig        = p_reord[0]*lw + p_reord[2]*sw
                current_signal = 0.5*hmm_sig if current_sigma > 0.03 else hmm_sig
                current_regime = int(np.argmax(p_reord))

            except Exception as e:
                print(f"[t={t} {data.index[t].date()}] HMM fit failed: {e}")
                # keep prior current_signal/regime/sigma

    # apply daily P&L
    r_next = log_returns[t+1]
    cost   = transaction_cost * abs(current_signal - (positions[-1] if positions else 0.0))
    pnl    = current_signal * r_next - cost

    positions.append(current_signal)
    returns_strategy.append(pnl)
    regimes_rolling.append(current_regime)
    dates.append(data.index[t+1])

# --- Step 4: Build results
df_hmm = pd.DataFrame({
    'Date': dates,
    'Position': positions,
    'Return_Strategy': returns_strategy,
    'Regime': regimes_rolling
}).set_index('Date')

df_hmm['Cumulative_Strategy'] = (1 + df_hmm['Return_Strategy']).cumprod()
df_hmm['Cumulative_Market']   = (1 + data['Log_Returns'].loc[df_hmm.index]).cumprod()

# --- Step 5: Metrics
daily    = df_hmm['Return_Strategy']
mean_ann = daily.mean() * 252
vol_ann  = daily.std()  * np.sqrt(252)
sharpe   = mean_ann / vol_ann

print("SV‚ÄëHMM Approx. with daily P&L & costs")
print(f"Annual Return    = {mean_ann:.2%}")
print(f"Annual Volatility= {vol_ann:.2%}")
print(f"Sharpe Ratio     = {sharpe:.2f}")
print(f"Last œÉ forecast  = {current_sigma:.4f}")

# --- Step 6: Plot
plt.figure(figsize=(12,6))
plt.plot(df_hmm.index, df_hmm['Cumulative_Market'],   '--', label='Buy & Hold')
plt.plot(df_hmm.index, df_hmm['Cumulative_Strategy'],  label='SV‚ÄëHMM Strat')
plt.legend(); plt.title("SV‚ÄëHMM Strategy vs. Buy & Hold")
plt.grid(True); plt.tight_layout()
plt.show()
 
 
